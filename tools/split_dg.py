#!/usr/bin/env python3

################################################################################
"""
Contact:    wlee9829@gmail.com 
Date:       2025_05_06 
Python:     python3.11
Script:     split_dg.py

This script is used to separate overlapped DGs generated by CRSSANT. For 
complex regions that exhibit unique duplex structures (DGs), multiple 
structural components (e.g., secondary structures, bulges, or unpaired regions)
within the same region may be masked by the current approach that groups
duplexes by percentage overlap.

Additionally, SHAPE reactivity profiles can be used to address length
variability in complex structures. Peaks correspond to regions of RNA that are 
less structured or involve transitions between secondary structure elements 
(e.g., loops or bulges). We will use reactivity thresholds to differentiate
between highly structured (low reactivity) and less structured (high 
reactivity) regions. The idea is that regions with complex structures may
show greater variability in reactivity compared to simple, stable duplexes.
Therefore, there should be a distinct bimodal/trimodal distribution in the
reactivity profile.

In summary, if a duplex has a length outside the average range of the DG
(either too short or too long) and shows a bimodal or trimodal SHAPE reactivity
distribution, we classify it as a complex or unique DG for deeper analysis.

LOGIC: 

1.  Identify candidate duplexes

    - Sort and order duplexes for independent processing 
    - Store duplex as tuple (start, end) to compare 
    - Calculate length of each DG, then average length

        AvgDG (Avg DG = sigma n, i=1 endi - starti) / n n = number of DGs, start
        and end are the positions of each DG

        Threshold distance (+/- 10% of the AvgDG to determine which DGs deviate)

        Threshold Lower = Avg - Avg * 0.1 Threshold Upper = Avg + Avg * 0.1

    - Classify based on length (if within threshold, considered normal) -
      Outside (shorter or longer) may be nested or unique 

    - For every overlap that occurs, assess the nature of the overlap. 
        
        If outlier duplex is entirely contained within another, consider it
        nested. If outlier duplex doesn’t overlap or only partially
        overlaps, it might be a distinct feature (e.g., a unique secondary
        structure or noncanonical duplex). If overlaps are detected, treat
        the outliers as unique and attempt to “split” the overlapping DGs.
        Ådjust boundaries of the duplexes: 

        If a duplex is considered a nested outlier, adjust its boundary by
        trimming the overlap and assigning it as    a distinct region. Once
        nested duplexes are split and resolved, output the final list of
        non-overlapping, detangled duplexes.

2. Define further parameters/rules

3. Integrate SHAPE data for experiments where possible

TO DO: 

    1.  Integrate into CRSSANT_birch 
    2.  Flag for setting different cutoffs 
    3.  Integrate icSHAPE data, use Gaussian Mixture Models (GMM) or kernel
        density estimation) to fit reactivity profile and determine number of
        distinct peaks.
"""
################################################################################


################################################################################
# Define version
__version__ = "2.0.0"

# Version notes
__update_notes__ = """
2.0.0
    -   Added new function to split DGs into separate files ()

1.2.0
    -   Implemented functions to write out statistics (-s, --stats)
        write_statistics_csv
        write_deviation_summary_csv

1.1.0
    -   Added threshold setting for classify_arm_deviations(-t, --threshold)

1.0.0
    -   Initial commit for function logic.
    -   extract_dgs reads bam file, returns statistics on DGs.
    -   classify_arm_deviations provides logic for categorizing arm lengths.
"""
################################################################################


################################################################################
# Import packages 
import argparse 
import csv
import math 
import os 
import pysam
import subprocess 
import sys
from collections import defaultdict
from statistics import mean, median
################################################################################


################################################################################
# Define sub-functions
def extract_dgs(bam_file):
    """
    Extract left and right arm lengths of split reads from CIGAR string,
    grouped by the integer at the end of the 'DG' tag.
    Returns: dict {DG: {'count': int, 'left_mean': float, 'left_median': float, 'right_mean': float, 'right_median': float}}
    """
    bamfile = pysam.AlignmentFile(bam_file, "rb")
    dg_groups = defaultdict(lambda: {'left': [], 'right': []})

    for read in bamfile:
        try:
            # Parse DG tag
            dg_tag = read.get_tag('DG')
            dg_fields = [field.strip() for field in dg_tag.split(',')]
            if len(dg_fields) != 3: continue

            dg_name = f"{dg_fields[0]}_{dg_fields[1]}_{dg_fields[2]}"

            # Parse CIGAR
            cigar = read.cigartuples
            if cigar is None: continue

            # Identify arms based on the first N
            left_len, right_len = 0, 0
            found_N = False

            for op, length in cigar:
                if op == 0:  # M = alignment match (0)
                    if not found_N: left_len += length
                    else: right_len += length
                elif op == 3:  # N = skipped region (gap)
                    found_N = True  # Start right arm after N

            if found_N and (left_len > 0 and right_len > 0):
                dg_groups[dg_name]['left'].append(left_len)
                dg_groups[dg_name]['right'].append(right_len)

        except (KeyError, ValueError, AttributeError):
            continue

    # Compute statistics
    dg_stats = {
        dg: {
            'count': len(vals['left']),
            'left_mean': round(mean(vals['left']), 2),
            'left_median': median(vals['left']),
            'right_mean': round(mean(vals['right']), 2),
            'right_median': median(vals['right']),
        }
        for dg, vals in dg_groups.items()
        if len(vals['left']) > 0 and len(vals['right']) > 0
    }

    return dg_groups, dg_stats

def classify_arm_deviations(dg_groups, dg_stats, threshold=0.25, use_mean=False):
    """
    Classify each DG read arm as high/low/normal relative to its group's mean/median.
    Returns: dict with detailed arm deviation counts.
    """
    arm_deviation_summary = {}

    for dg_name, arms in dg_groups.items():
        left_lengths = arms['left']
        right_lengths = arms['right']
        total_reads = len(left_lengths)

        if total_reads == 0: continue

        # Reference values
        left_ref = dg_stats[dg_name]['left_mean'] if use_mean else dg_stats[dg_name]['left_median']
        right_ref = dg_stats[dg_name]['right_mean'] if use_mean else dg_stats[dg_name]['right_median']

        summary = {
            'total': total_reads,
            'left_high': 0, 'left_low': 0, 'left_normal': 0,
            'right_high': 0, 'right_low': 0, 'right_normal': 0
        }

        for left_len, right_len in zip(left_lengths, right_lengths):

            # Left arm deviation
            left_ratio = (left_len - left_ref) / left_ref
            if left_ratio > threshold: summary['left_high'] += 1
            elif left_ratio < -threshold: summary['left_low'] += 1
            else: summary['left_normal'] += 1

            # Right arm deviation
            right_ratio = (right_len - right_ref) / right_ref
            if right_ratio > threshold: summary['right_high'] += 1
            elif right_ratio < -threshold: summary['right_low'] += 1
            else: summary['right_normal'] += 1

        arm_deviation_summary[dg_name] = summary

    return arm_deviation_summary

def write_statistics_csv(dg_stats, output_path):
    """
    Write DG statistics to CSV.
    """
    with open(output_path, mode='w', newline='') as csvfile:
        fieldnames = ['dg_name', 'total_count', 'left_mean', 'left_median', 
            'right_mean', 'right_median']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        for dg_name, stats in dg_stats.items():
            writer.writerow({
                'dg_name': dg_name,
                'total_count': stats['count'],
                'left_mean': stats['left_mean'],
                'left_median': stats['left_median'],
                'right_mean': stats['right_mean'],
                'right_median': stats['right_median']
            })

def write_deviation_summary_csv(arm_summary, output_path):
    """
    Write DG arm deviation summary to CSV.
    """
    with open(output_path, mode='w', newline='') as csvfile:
        fieldnames = [
            'dg_name', 'total_count',
            'left_high', 'left_low', 'left_normal',
            'right_high', 'right_low', 'right_normal'
        ]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        for dg_name, summary in arm_summary.items():
            row = {'dg_name': dg_name, 'total_count': summary['total']}
            row.update({k: summary[k] for k in fieldnames if k in summary})
            writer.writerow(row)

def parse_arguments():
    """
    Set up command line arguments.
    """
    parser = argparse.ArgumentParser(
        description='Process DGs to isolate XLRNA interactions.',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    
    subparsers= parser.add_subparsers(dest='command', help='Sub-commands')

    process_DGs = subparsers.add_parser('process_input', 
        help='Processes DG bam files generated after CRSSANT')
    process_DGs.add_argument('-i', '--input', required=True, 
        help='Input DG BAM file')
    process_DGs.add_argument('--use-mean', action='store_true')
    process_DGs.add_argument('-t', '--threshold', type=float, default=0.25)
    process_DGs.add_argument('-s', '--stats', action='store_true')

    return parser.parse_args()
################################################################################


################################################################################
# Execute main

def main():
    args = parse_arguments()
    try: nproc = subprocess.run(
        "nproc", shell=True, check=True, text=True, capture_output=True)
        n_threads = int(nproc.stdout.strip())

    except subprocess.CalledProcessError:
        try: n_threads = os.cpu_count()
        except Exception as e:
            print(  f"Error in retrieving CPU count: {e}. "
                    f"Defaulting to 1 thread.")
            n_threads = 1

    if args.command == 'process_input':
        # Extract both read data and statistics
        dg_groups, dg_stats = extract_dgs(bam_file=args.input)
        print("\n=== DG Statistics ===")
        for dg, metrics in dg_stats.items():
            print(f"DG={dg}: {metrics}")

        # Run deviation classifier
        deviations = classify_arm_deviations(dg_groups, dg_stats, 
            threshold=args.threshold, use_mean=args.use_mean)

        print(f"\n=== Arm Deviation Summary ({int(args.threshold * 100)}% "
            f"from {'median' if args.use_mean else 'mean'}) ===")
        for dg, summary in deviations.items(): print(f"DG={dg}: {summary}")

        if args.stats:
            base_name = os.path.splitext(os.path.basename(args.input))[0]
            stats_csv = f"{base_name}_dg_statistics.csv"
            deviations_csv = f"{base_name}_arm_deviations.csv"

            # Write CSVs
            write_statistics_csv(dg_stats, stats_csv)
            write_deviation_summary_csv(deviations, deviations_csv)

            print(f"\n[+] DG statistics written to: {stats_csv}")
            print(f"[+] Arm deviation summary written to: {deviations_csv}")

if __name__ == "__main__":
    main()
################################################################################